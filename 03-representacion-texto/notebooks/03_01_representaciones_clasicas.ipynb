{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c461caa",
   "metadata": {},
   "source": [
    "# Tema 3: Representaciones clásicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_d44cd0e7",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Bolsa de Palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b1c8d8",
   "metadata": {},
   "source": [
    "### Apartado a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d44cd0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['de ejemplo' 'de febrero' 'de un' 'del año' 'ejemplo que' 'en febrero'\n",
      " 'es una' 'estamos finales' 'esto es' 'febrero sigue' 'finales de'\n",
      " 'frase de' 'habla de' 'haciendo frío' 'mes del' 'que habla'\n",
      " 'sigue haciendo' 'un mes' 'una frase']\n",
      "Document-Term Matrix:\n",
      " [[0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0]\n",
      " [1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# Corpus de ejemplo\n",
    "corpus = [\n",
    "    \"Estamos a finales de febrero.\",\n",
    "    \"En febrero sigue haciendo frío.\",\n",
    "    \"Esto es una frase de ejemplo que habla de un mes del año.\",\n",
    "]\n",
    "\n",
    "# Crear el modelo de bolsa de palabras con bigramas\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Mostrar los nombres de las características y la matriz documento-término\n",
    "print(\"Feature Names:\", vectorizer.get_feature_names_out())\n",
    "print(\"Document-Term Matrix:\\n\", matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ade2139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['año' 'de' 'de ejemplo' 'de ejemplo que' 'de febrero' 'de un' 'de un mes'\n",
      " 'del' 'del año' 'ejemplo' 'ejemplo que' 'ejemplo que habla' 'en'\n",
      " 'en febrero' 'en febrero sigue' 'es' 'es una' 'es una frase' 'estamos'\n",
      " 'estamos finales' 'estamos finales de' 'esto' 'esto es' 'esto es una'\n",
      " 'febrero' 'febrero sigue' 'febrero sigue haciendo' 'finales' 'finales de'\n",
      " 'finales de febrero' 'frase' 'frase de' 'frase de ejemplo' 'frío' 'habla'\n",
      " 'habla de' 'habla de un' 'haciendo' 'haciendo frío' 'mes' 'mes del'\n",
      " 'mes del año' 'que' 'que habla' 'que habla de' 'sigue' 'sigue haciendo'\n",
      " 'sigue haciendo frío' 'un' 'un mes' 'un mes del' 'una' 'una frase'\n",
      " 'una frase de']\n",
      "Document-Term Matrix:\n",
      " [[0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0\n",
      "  0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0]\n",
      " [1 2 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 1\n",
      "  1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Corpus de ejemplo\n",
    "corpus = [\n",
    "    \"Estamos a finales de febrero.\",\n",
    "    \"En febrero sigue haciendo frío.\",\n",
    "    \"Esto es una frase de ejemplo que habla de un mes del año.\",\n",
    "]\n",
    "\n",
    "# Crear el modelo de bolsa de palabras con bigramas\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Mostrar los nombres de las características y la matriz documento-término\n",
    "print(\"Feature Names:\", vectorizer.get_feature_names_out())\n",
    "print(\"Document-Term Matrix:\\n\", matrix.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_8d1b2214",
   "metadata": {},
   "source": [
    "### Apartado b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3177ea01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bird' 'cat' 'flying' 'in' 'jumped' 'roared' 'sky' 'the' 'tiger' 'white']\n",
      "[[0 1 0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 1 1 1]\n",
      " [1 0 1 1 0 0 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Documentos de ejemplo\n",
    "docs = [\"The cat jumped cat\", \"The white tiger roared\", \"Bird flying in the sky\"]\n",
    "\n",
    "# Crear un objeto CountVectorizer con representacion binaria\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "# Usar el método fit_transform para transformar los documentos en una matriz binaria\n",
    "binary = vectorizer.fit_transform(docs)\n",
    "\n",
    "# Mostrar el vocabulario (características) de la matriz binaria\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "# Mostrar la matriz binaria\n",
    "print(binary.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17281fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bird' 'cat' 'flying' 'in' 'jumped' 'roared' 'sky' 'the' 'tiger' 'white']\n",
      "[[0 2 0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 1 1 1]\n",
      " [1 0 1 1 0 0 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Documentos de ejemplo\n",
    "docs = [\"The cat jumped cat\", \"The white tiger roared\", \"Bird flying in the sky\"]\n",
    "\n",
    "# Crear un objeto CountVectorizer con frecuencias por termino\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Usar el método fit_transform para transformar los documentos en una matriz frecuencias\n",
    "frequencies = vectorizer.fit_transform(docs)\n",
    "\n",
    "# Mostrar el vocabulario (características) de la matriz frecuencias\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "# Mostrar la matriz frecuencias\n",
    "print(frequencies.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d1b2214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bird' 'cat' 'flying' 'in' 'jumped' 'roared' 'sky' 'the' 'tiger' 'white']\n",
      "[[0.         0.86477018 0.         0.         0.43238509 0.\n",
      "  0.         0.2553736  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.54645401\n",
      "  0.         0.32274454 0.54645401 0.54645401]\n",
      " [0.47952794 0.         0.47952794 0.47952794 0.         0.\n",
      "  0.47952794 0.28321692 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Documentos de ejemplo\n",
    "docs = [\"The cat jumped cat\", \"The white tiger roared\", \"Bird flying in the sky\"]\n",
    "\n",
    "# Crear un objeto TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Usar el método fit_transform para transformar los documentos en una matriz TF-IDF\n",
    "tfidf = vectorizer.fit_transform(docs)\n",
    "\n",
    "# Mostrar el vocabulario (características) de la matriz TF-IDF\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "# Mostrar la matriz TF-IDF\n",
    "print(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_5a81ebed",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Matriz de coocurrencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36c29d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Descargar recursos de NLTK\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6be34c9",
   "metadata": {},
   "source": [
    "### Apartado a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70527ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mysterious tunnels sketched by Leonardo da Vinci in the late 1400s may have been found at the Castle. Secret tunnels at the Sforza Castle.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Texto de ejemplo\n",
    "text = \"Mysterious tunnels sketched by Leonardo da Vinci in the late 1400s may have been found at the Castle. Secret tunnels at the Sforza Castle.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41ae997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se preprocesa el texto, eliminando stopwords, convirtiendo las palabras a minúsculas, tokenizando y eliminando los tokens no alfanuméricos\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "words = word_tokenize(text.lower())\n",
    "words = [word for word in words if word.isalnum() and word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b876a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define el tamaño de ventana y se crea la lista de pares que coocurren dentro de la ventana\n",
    "\n",
    "# Definir el tamaño de ventana para la coocurrencia\n",
    "window_size = 2\n",
    "\n",
    "# Crear una lista de pares de palabras que coocurren\n",
    "co_occurrences = defaultdict(Counter)\n",
    "for i, word in enumerate(words):\n",
    "    for j in range(max(0, i - window_size), min(len(words), i + window_size + 1)):\n",
    "        if i != j:\n",
    "            co_occurrences[word][words[j]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b77914ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtiene el vocabulario\n",
    "# Crear una lista de palabras únicas\n",
    "unique_words = list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d44623e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea la matriz de coocurrencia\n",
    "# Inicializar la matriz de coocurrencias\n",
    "co_matrix = np.zeros((len(unique_words), len(unique_words)), dtype=int)\n",
    "\n",
    "# Poblar la matriz de coocurrencias\n",
    "word_index = {word: idx for idx, word in enumerate(unique_words)}\n",
    "for word, neighbors in co_occurrences.items():\n",
    "    for neighbor, count in neighbors.items():\n",
    "        co_matrix[word_index[word]][word_index[neighbor]] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67b50fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>found</th>\n",
       "      <th>1400s</th>\n",
       "      <th>leonardo</th>\n",
       "      <th>mysterious</th>\n",
       "      <th>vinci</th>\n",
       "      <th>castle</th>\n",
       "      <th>tunnels</th>\n",
       "      <th>sforza</th>\n",
       "      <th>late</th>\n",
       "      <th>secret</th>\n",
       "      <th>sketched</th>\n",
       "      <th>da</th>\n",
       "      <th>may</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>found</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400s</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leonardo</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mysterious</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinci</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>castle</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tunnels</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sforza</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>late</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>secret</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sketched</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>may</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            found  1400s  leonardo  mysterious  vinci  castle  tunnels  \\\n",
       "found           0      1         0           0      0       1        0   \n",
       "1400s           1      0         0           0      1       0        0   \n",
       "leonardo        0      0         0           0      1       0        1   \n",
       "mysterious      0      0         0           0      0       0        1   \n",
       "vinci           0      1         1           0      0       0        0   \n",
       "castle          1      0         0           0      0       0        2   \n",
       "tunnels         0      0         1           1      0       2        0   \n",
       "sforza          0      0         0           0      0       1        1   \n",
       "late            0      1         0           0      1       0        0   \n",
       "secret          1      0         0           0      0       1        1   \n",
       "sketched        0      0         1           1      0       0        1   \n",
       "da              0      0         1           0      1       0        0   \n",
       "may             1      1         0           0      0       1        0   \n",
       "\n",
       "            sforza  late  secret  sketched  da  may  \n",
       "found            0     0       1         0   0    1  \n",
       "1400s            0     1       0         0   0    1  \n",
       "leonardo         0     0       0         1   1    0  \n",
       "mysterious       0     0       0         1   0    0  \n",
       "vinci            0     1       0         0   1    0  \n",
       "castle           1     0       1         0   0    1  \n",
       "tunnels          1     0       1         1   0    0  \n",
       "sforza           0     0       1         0   0    0  \n",
       "late             0     0       0         0   1    1  \n",
       "secret           1     0       0         0   0    0  \n",
       "sketched         0     0       0         0   1    0  \n",
       "da               0     1       0         1   0    0  \n",
       "may              0     1       0         0   0    0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se crea un DataFrame para una mejor visualización\n",
    "# Crear un DataFrame para una mejor legibilidad\n",
    "co_matrix_df = pd.DataFrame(co_matrix, index=unique_words, columns=unique_words)\n",
    "\n",
    "# Mostrar la matriz de coocurrencias\n",
    "co_matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b07f5c",
   "metadata": {},
   "source": [
    "### Apartado b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c646a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La similitud del coseno entre las dos palabras es: 0.0\n",
      "La similitud del coseno entre las dos palabras es: 0.25\n",
      "La similitud del coseno entre las dos palabras es: 1.0\n",
      "La similitud del coseno entre las dos palabras es: 0.5\n",
      "La similitud del coseno entre las dos palabras es: 0.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def cosine_similarity_sklearn(matrix, word1_index, word2_index):\n",
    "    # Obtener los vectores de las dos palabras\n",
    "    vector1 = matrix[word1_index].reshape(1, -1)\n",
    "    vector2 = matrix[word2_index].reshape(1, -1)\n",
    "\n",
    "    # Calcular la similitud del coseno usando sklearn\n",
    "    similarity = cosine_similarity(vector1, vector2)[0][0]\n",
    "\n",
    "    return similarity\n",
    "\n",
    "\n",
    "# Calcular la similitud del coseno entre las palabras \"da\" y \"vinci\" (índices 8 y 9)\n",
    "similarity = cosine_similarity_sklearn(co_matrix, 8, 9)\n",
    "print(f\"La similitud del coseno entre las dos palabras es: {similarity}\")\n",
    "\n",
    "# Calcular la similitud del coseno entre las palabras \"may\" y \"tunnels\" (índices 0 y 4)\n",
    "similarity = cosine_similarity_sklearn(co_matrix, 0, 4)\n",
    "print(f\"La similitud del coseno entre las dos palabras es: {similarity}\")\n",
    "\n",
    "# Calcular la similitud del coseno entre una palabra consigo misma (índices 4 y 4)\n",
    "similarity = cosine_similarity_sklearn(co_matrix, 4, 4)\n",
    "print(f\"La similitud del coseno entre las dos palabras es: {similarity}\")\n",
    "\n",
    "# Calcular la similitud del coseno entre las palabras \"tunnels\" y \"castle\" (índices 4 y 12)\n",
    "similarity = cosine_similarity_sklearn(co_matrix, 4, 12)\n",
    "print(f\"La similitud del coseno entre las dos palabras es: {similarity}\")\n",
    "\n",
    "# Calcular la similitud del coseno entre las palabras \"secret\" y \"tunnels\" (índices 2 y 4)\n",
    "similarity = cosine_similarity_sklearn(co_matrix, 2, 4)\n",
    "print(f\"La similitud del coseno entre las dos palabras es: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b577525",
   "metadata": {},
   "source": [
    "### Apartado c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7da26a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las palabras más similares a  leonardo  son: {similar_words_indices}\n",
      "leonardo\n",
      "castle\n",
      "sforza\n",
      "da\n",
      "sketched\n",
      "Las palabras más similares a  da  son: {similar_words_indices}\n",
      "leonardo\n",
      "1400s\n",
      "found\n",
      "vinci\n",
      "da\n"
     ]
    }
   ],
   "source": [
    "def most_similar_words(matrix, word_index, n):\n",
    "    # Obtener el vector de la palabra dada\n",
    "    word_vector = matrix[word_index].reshape(1, -1)\n",
    "\n",
    "    # Calcular la similitud del coseno entre la palabra dada y todas las demás palabras\n",
    "    similarities = cosine_similarity(matrix, word_vector).flatten()\n",
    "\n",
    "    # Obtener los índices de las n palabras más similares (excluyendo la palabra dada)\n",
    "    most_similar_indices = similarities.argsort()[-n - 1 : -1][::-1]\n",
    "\n",
    "    return most_similar_indices\n",
    "\n",
    "\n",
    "n_words_most_similar = 5\n",
    "\n",
    "# Obtener los índices de las 3 palabras más similares a la palabra en el índice que corresponda\n",
    "word = \"leonardo\"\n",
    "similar_words_indices = most_similar_words(co_matrix, 3, n_words_most_similar)\n",
    "print(\"Las palabras más similares a \", word, \" son: {similar_words_indices}\")\n",
    "\n",
    "for index in similar_words_indices:\n",
    "    print(unique_words[index])\n",
    "\n",
    "\n",
    "word = \"da\"\n",
    "similar_words_indices = most_similar_words(co_matrix, 8, n_words_most_similar)\n",
    "print(\"Las palabras más similares a \", word, \" son: {similar_words_indices}\")\n",
    "\n",
    "for index in similar_words_indices:\n",
    "    print(unique_words[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e704d8fc",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a4f340",
   "metadata": {},
   "source": [
    "### Apartado a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "effac75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation \n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "# Suprimimos warnings para mayor claridad\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f9cc8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titular</th>\n",
       "      <th>Noticia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suspendido el partido Villarreal-Espanyol por ...</td>\n",
       "      <td>El temporal de lluvia y nieve afecta a áreas d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reino Unido y otros países aliados de Ucrania ...</td>\n",
       "      <td>Los países europeos de la OTAN y Canadá han de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los premios Oscar dan la gloria al cine indie ...</td>\n",
       "      <td>¿Qué premia exactamente Hollywood y su industr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emilia Pérez, Karla Sofía Gascón, Demi Moore y...</td>\n",
       "      <td>Fue Beckett el que, en un arrebato no precisam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Aemet retira también el aviso rojo por fuer...</td>\n",
       "      <td>La Agencia Estatal de Meteorología (Aemet) ha ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>España propone financiar la defensa de los paí...</td>\n",
       "      <td>España considera que la seguridad es un “Bien ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>El tequila lubricó la gran noche en la que Hol...</td>\n",
       "      <td>La bebida fluyó con abundancia en los cuatro n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Trump congela toda la ayuda militar a Ucrania ...</td>\n",
       "      <td>El presidente estadounidense, Donald Trump, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>La Comunidad Valenciana y otras cinco regiones...</td>\n",
       "      <td>Este martes seguirá arreciando en el este de l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Objetivo: acabar con la pesca fantasma y las r...</td>\n",
       "      <td>Dos biólogos de la Universitat de València par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Los científicos abandonan el sueño de crear ‘v...</td>\n",
       "      <td>Aunque los laboratorios de biología sintética ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Valladolid ya no permite más terrazas cerradas...</td>\n",
       "      <td>El Ayuntamiento espera ordenar este año la Pla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Titular  \\\n",
       "0   Suspendido el partido Villarreal-Espanyol por ...   \n",
       "1   Reino Unido y otros países aliados de Ucrania ...   \n",
       "2   Los premios Oscar dan la gloria al cine indie ...   \n",
       "3   Emilia Pérez, Karla Sofía Gascón, Demi Moore y...   \n",
       "4   La Aemet retira también el aviso rojo por fuer...   \n",
       "5   España propone financiar la defensa de los paí...   \n",
       "6   El tequila lubricó la gran noche en la que Hol...   \n",
       "7   Trump congela toda la ayuda militar a Ucrania ...   \n",
       "8   La Comunidad Valenciana y otras cinco regiones...   \n",
       "9   Objetivo: acabar con la pesca fantasma y las r...   \n",
       "10  Los científicos abandonan el sueño de crear ‘v...   \n",
       "11  Valladolid ya no permite más terrazas cerradas...   \n",
       "\n",
       "                                              Noticia  \n",
       "0   El temporal de lluvia y nieve afecta a áreas d...  \n",
       "1   Los países europeos de la OTAN y Canadá han de...  \n",
       "2   ¿Qué premia exactamente Hollywood y su industr...  \n",
       "3   Fue Beckett el que, en un arrebato no precisam...  \n",
       "4   La Agencia Estatal de Meteorología (Aemet) ha ...  \n",
       "5   España considera que la seguridad es un “Bien ...  \n",
       "6   La bebida fluyó con abundancia en los cuatro n...  \n",
       "7   El presidente estadounidense, Donald Trump, ha...  \n",
       "8   Este martes seguirá arreciando en el este de l...  \n",
       "9   Dos biólogos de la Universitat de València par...  \n",
       "10  Aunque los laboratorios de biología sintética ...  \n",
       "11  El Ayuntamiento espera ordenar este año la Pla...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construir ruta al archivo de datos\n",
    "PATH_DATA = Path.cwd().parent / 'data'\n",
    "\n",
    "# Lista de textos a procesar\n",
    "with open(PATH_DATA / 'Noticias.json', encoding=\"utf8\") as json_file:\n",
    "    datos = json.load(json_file)\n",
    "\n",
    "tuplas = list(\n",
    "    zip(\n",
    "        [noticia.get(\"Title\") for noticia in datos],\n",
    "        [noticia.get(\"TextContent\") for noticia in datos],\n",
    "    )\n",
    ")\n",
    "df = pd.DataFrame(tuplas, columns=[\"Titular\", \"Noticia\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab934eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas del preprocesamiento:\n",
      "- Tamaño del vocabulario: 390 palabras únicas\n",
      "- Dimensiones de la matriz: (12, 390)\n",
      "\n",
      "Palabras más frecuentes:\n",
      "- que: 15 apariciones\n",
      "- los: 12 apariciones\n",
      "- del: 9 apariciones\n",
      "- para: 9 apariciones\n",
      "- las: 8 apariciones\n",
      "- una: 8 apariciones\n",
      "- por: 8 apariciones\n",
      "- con: 7 apariciones\n",
      "- han: 6 apariciones\n",
      "- este: 5 apariciones\n"
     ]
    }
   ],
   "source": [
    "# Lista de textos a procesar\n",
    "documents = df[\"Noticia\"].tolist()\n",
    "\n",
    "# Configurar y crear el vectorizador\n",
    "tf_vectorizer = CountVectorizer(\n",
    "    stop_words=[],  # No eliminamos stopwords por ahora []\n",
    "    min_df=1,  # Incluir palabras que aparecen al menos 1 vez\n",
    "    max_df=1.0,  # Sin límite superior de frecuencia\n",
    "    lowercase=True,  # Convertir todo a minúsculas\n",
    "    max_features=50000,  # Máximo número de palabras a considerar\n",
    "    token_pattern=\"[a-zA-Z0-9]{3,}\",  # Palabras de 3+ caracteres\n",
    "    analyzer=\"word\",\n",
    ")\n",
    "\n",
    "# Crear la matriz de documentos-términos\n",
    "bag_of_words = tf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Obtener el vocabulario\n",
    "dictionary = tf_vectorizer.get_feature_names_out()\n",
    "vocabulary = tf_vectorizer.vocabulary_\n",
    "\n",
    "print(\"Estadísticas del preprocesamiento:\")\n",
    "print(f\"- Tamaño del vocabulario: {len(dictionary)} palabras únicas\")\n",
    "print(f\"- Dimensiones de la matriz: {bag_of_words.shape}\")\n",
    "\n",
    "# Mostrar las palabras más frecuentes\n",
    "word_freq = bag_of_words.sum(axis=0).A1\n",
    "top_words_idx = word_freq.argsort()[-10:][::-1]\n",
    "print(\"\\nPalabras más frecuentes:\")\n",
    "for idx in top_words_idx:\n",
    "    print(f\"- {dictionary[idx]}: {word_freq[idx]} apariciones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb20a8c",
   "metadata": {},
   "source": [
    "**Entrenamiento LDA**\n",
    "\n",
    "El algoritmo LDA tiene varios hiperparámetros importantes:\n",
    "\n",
    "* n_topics: Número de tópicos a encontrar\n",
    "    - Debe elegirse según el conocimiento del dominio\n",
    "    - Se puede optimizar usando métricas como coherencia o perplejidad\n",
    "\n",
    "* alpha: Prior de la distribución documentos-tópicos\n",
    "    - alpha < 1: documentos se concentran en pocos tópicos\n",
    "    - alpha > 1: documentos mezclan varios tópicos\n",
    "    - alpha = 1: distribución uniforme\n",
    "\n",
    "* beta: Prior de la distribución tópicos-palabras\n",
    "    - beta < 1: tópicos más específicos (pocas palabras)\n",
    "    - beta > 1: tópicos más generales (muchas palabras)\n",
    "    - beta = 1: distribución uniforme\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33a89e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración del modelo LDA:\n",
      "- Número de tópicos: 2\n",
      "- Alpha: 1.0\n",
      "- Beta: 0.1\n",
      "\n",
      "Iniciando entrenamiento...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 25, perplexity: 2758.9888\n",
      "iteration: 2 of max_iter: 25, perplexity: 2360.5562\n",
      "iteration: 3 of max_iter: 25, perplexity: 2063.0452\n",
      "iteration: 4 of max_iter: 25, perplexity: 1844.5082\n",
      "iteration: 5 of max_iter: 25, perplexity: 1679.1945\n",
      "iteration: 6 of max_iter: 25, perplexity: 1550.3955\n",
      "iteration: 7 of max_iter: 25, perplexity: 1447.6857\n",
      "iteration: 8 of max_iter: 25, perplexity: 1364.3213\n",
      "iteration: 9 of max_iter: 25, perplexity: 1295.7429\n",
      "iteration: 10 of max_iter: 25, perplexity: 1238.7427\n",
      "iteration: 11 of max_iter: 25, perplexity: 1190.9847\n",
      "iteration: 12 of max_iter: 25, perplexity: 1150.7174\n",
      "iteration: 13 of max_iter: 25, perplexity: 1116.5946\n",
      "iteration: 14 of max_iter: 25, perplexity: 1087.5606\n",
      "iteration: 15 of max_iter: 25, perplexity: 1062.7727\n",
      "iteration: 16 of max_iter: 25, perplexity: 1041.5487\n",
      "iteration: 17 of max_iter: 25, perplexity: 1023.3301\n",
      "iteration: 18 of max_iter: 25, perplexity: 1007.6550\n",
      "iteration: 19 of max_iter: 25, perplexity: 994.1387\n",
      "iteration: 20 of max_iter: 25, perplexity: 982.4586\n",
      "iteration: 21 of max_iter: 25, perplexity: 972.3433\n",
      "iteration: 22 of max_iter: 25, perplexity: 963.5633\n",
      "iteration: 23 of max_iter: 25, perplexity: 955.9239\n",
      "iteration: 24 of max_iter: 25, perplexity: 949.2601\n",
      "iteration: 25 of max_iter: 25, perplexity: 943.4313\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(doc_topic_prior=1.0, evaluate_every=1,\n",
       "                          learning_method=&#x27;online&#x27;, max_iter=25, n_components=2,\n",
       "                          n_jobs=-1, random_state=0, topic_word_prior=0.1,\n",
       "                          verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LatentDirichletAllocation</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\">?<span>Documentation for LatentDirichletAllocation</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_components',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=n_components,-int%2C%20default%3D10\">\n",
       "            n_components\n",
       "            <span class=\"param-doc-description\">n_components: int, default=10<br><br>Number of topics.<br><br>.. versionchanged:: 0.19<br>    ``n_topics`` was renamed to ``n_components``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('doc_topic_prior',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=doc_topic_prior,-float%2C%20default%3DNone\">\n",
       "            doc_topic_prior\n",
       "            <span class=\"param-doc-description\">doc_topic_prior: float, default=None<br><br>Prior of document topic distribution `theta`. If the value is None,<br>defaults to `1 / n_components`.<br>In [1]_, this is called `alpha`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('topic_word_prior',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=topic_word_prior,-float%2C%20default%3DNone\">\n",
       "            topic_word_prior\n",
       "            <span class=\"param-doc-description\">topic_word_prior: float, default=None<br><br>Prior of topic word distribution `beta`. If the value is None, defaults<br>to `1 / n_components`.<br>In [1]_, this is called `eta`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=learning_method,-%7B%27batch%27%2C%20%27online%27%7D%2C%20default%3D%27batch%27\">\n",
       "            learning_method\n",
       "            <span class=\"param-doc-description\">learning_method: {'batch', 'online'}, default='batch'<br><br>Method used to update `_component`. Only used in :meth:`fit` method.<br>In general, if the data size is large, the online update will be much<br>faster than the batch update.<br><br>Valid options:<br><br>- 'batch': Batch variational Bayes method. Use all training data in each EM<br>  update. Old `components_` will be overwritten in each iteration.<br>- 'online': Online variational Bayes method. In each EM update, use mini-batch<br>  of training data to update the ``components_`` variable incrementally. The<br>  learning rate is controlled by the ``learning_decay`` and the<br>  ``learning_offset`` parameters.<br><br>.. versionchanged:: 0.20<br>    The default learning method is now ``\"batch\"``.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;online&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_decay',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=learning_decay,-float%2C%20default%3D0.7\">\n",
       "            learning_decay\n",
       "            <span class=\"param-doc-description\">learning_decay: float, default=0.7<br><br>It is a parameter that control learning rate in the online learning<br>method. The value should be set between (0.5, 1.0] to guarantee<br>asymptotic convergence. When the value is 0.0 and batch_size is<br>``n_samples``, the update method is same as batch learning. In the<br>literature, this is called kappa.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_offset',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=learning_offset,-float%2C%20default%3D10.0\">\n",
       "            learning_offset\n",
       "            <span class=\"param-doc-description\">learning_offset: float, default=10.0<br><br>A (positive) parameter that downweights early iterations in online<br>learning.  It should be greater than 1.0. In the literature, this is<br>called tau_0.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">10.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=max_iter,-int%2C%20default%3D10\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=10<br><br>The maximum number of passes over the training data (aka epochs).<br>It only impacts the behavior in the :meth:`fit` method, and not the<br>:meth:`partial_fit` method.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">25</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('batch_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=batch_size,-int%2C%20default%3D128\">\n",
       "            batch_size\n",
       "            <span class=\"param-doc-description\">batch_size: int, default=128<br><br>Number of documents to use in each EM iteration. Only used in online<br>learning.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">128</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('evaluate_every',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=evaluate_every,-int%2C%20default%3D-1\">\n",
       "            evaluate_every\n",
       "            <span class=\"param-doc-description\">evaluate_every: int, default=-1<br><br>How often to evaluate perplexity. Only used in `fit` method.<br>set it to 0 or negative number to not evaluate perplexity in<br>training at all. Evaluating perplexity can help you check convergence<br>in training process, but it will also increase total training time.<br>Evaluating perplexity in every iteration might increase training time<br>up to two-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('total_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=total_samples,-int%2C%20default%3D1e6\">\n",
       "            total_samples\n",
       "            <span class=\"param-doc-description\">total_samples: int, default=1e6<br><br>Total number of documents. Only used in the :meth:`partial_fit` method.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000000.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('perp_tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=perp_tol,-float%2C%20default%3D1e-1\">\n",
       "            perp_tol\n",
       "            <span class=\"param-doc-description\">perp_tol: float, default=1e-1<br><br>Perplexity tolerance. Only used when ``evaluate_every`` is greater than 0.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('mean_change_tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=mean_change_tol,-float%2C%20default%3D1e-3\">\n",
       "            mean_change_tol\n",
       "            <span class=\"param-doc-description\">mean_change_tol: float, default=1e-3<br><br>Stopping tolerance for updating document topic distribution in E-step.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_doc_update_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=max_doc_update_iter,-int%2C%20default%3D100\">\n",
       "            max_doc_update_iter\n",
       "            <span class=\"param-doc-description\">max_doc_update_iter: int, default=100<br><br>Max number of iterations for updating document topic distribution in<br>the E-step.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to use in the E-step.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>Verbosity level.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Pass an int for reproducible results across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(doc_topic_prior=1.0, evaluate_every=1,\n",
       "                          learning_method='online', max_iter=25, n_components=2,\n",
       "                          n_jobs=-1, random_state=0, topic_word_prior=0.1,\n",
       "                          verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parámetros del modelo\n",
    "n_topics = 2  # Número moderado de tópicos para empezar\n",
    "alpha = 1.0  # Documentos algo especializados\n",
    "beta = 0.1  # Tópicos bastante específicos\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "print(\"Configuración del modelo LDA:\")\n",
    "print(f\"- Número de tópicos: {n_topics}\")\n",
    "print(f\"- Alpha: {alpha}\")\n",
    "print(f\"- Beta: {beta}\")\n",
    "print(\"\\nIniciando entrenamiento...\\n\")\n",
    "\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics,  # Número de tópicos\n",
    "    doc_topic_prior=alpha,  # Prior documentos-tópicos\n",
    "    topic_word_prior=beta,  # Prior tópicos-palabras\n",
    "    max_iter=25,  # Máximo de iteraciones\n",
    "    learning_method=\"online\",  # Método de aprendizaje\n",
    "    evaluate_every=1,  # Evaluar en cada iteración\n",
    "    n_jobs=-1,  # Usar todos los cores\n",
    "    random_state=0,  # Semilla para reproducibilidad\n",
    "    verbose=1,  # Mostrar progreso\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "lda.fit(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bf5dcd",
   "metadata": {},
   "source": [
    "**Análisis de Resultados**\n",
    "\n",
    "Se analizan los resultados de tres formas diferentes:\n",
    "\n",
    "* Palabras más relevantes por tópico\n",
    "* Documentos más representativos de cada tópico\n",
    "* Distribución de tópicos en documentos específicos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c570ef83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TÓPICOS DESCUBIERTOS\n",
      "Cada tópico se representa por sus palabras más probables\n",
      "\n",
      " Tópico 1:\n",
      "   que: 7.7820\n",
      "   por: 5.1884\n",
      "   los: 5.0778\n",
      "   han: 5.0076\n",
      "   las: 4.0323\n",
      "   horas: 3.5345\n",
      "   para: 3.0125\n",
      "   rojo: 3.0002\n",
      "   meteorolog: 2.4789\n",
      "   provincia: 2.4727\n",
      "\n",
      " Tópico 2:\n",
      "   del: 7.8142\n",
      "   que: 6.8644\n",
      "   los: 6.7025\n",
      "   una: 6.0120\n",
      "   para: 5.8943\n",
      "   con: 4.9902\n",
      "   este: 4.8988\n",
      "   las: 3.9034\n",
      "   ses: 3.0481\n",
      "   verdad: 2.9999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuración de visualización\n",
    "no_top_words = 10  # Número de palabras top por tópico\n",
    "no_top_documents = 2  # Número de documentos top por tópico\n",
    "\n",
    "# Obtener las distribuciones\n",
    "doc_topics = lda.transform(bag_of_words)  # Distribución de tópicos por documento\n",
    "topics = lda.components_  # Distribución de palabras por tópico\n",
    "\n",
    "\n",
    "# 1. Detallar tópicos encontrados\n",
    "print(\"TÓPICOS DESCUBIERTOS\")\n",
    "print(\"Cada tópico se representa por sus palabras más probables\\n\")\n",
    "\n",
    "for topic_idx, topic in enumerate(topics):\n",
    "    print(f\" Tópico {topic_idx + 1}:\")\n",
    "    # Obtener índices de las palabras más probables\n",
    "    top_words_idx = topic.argsort()[: -no_top_words - 1 : -1]\n",
    "    top_words = [dictionary[i] for i in top_words_idx]\n",
    "    top_probs = [topic[i] for i in top_words_idx]\n",
    "\n",
    "    # Mostrar palabras y sus probabilidades\n",
    "\n",
    "    for word, prob in zip(top_words, top_probs):\n",
    "        print(f\"   {word}: {prob:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ada1b249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DOCUMENTOS MÁS REPRESENTATIVOS POR TÓPICO\n",
      "Se muestran los documentos que más peso tienen en cada tópico\n",
      "\n",
      " Tópico 1:\n",
      "   'Suspendido el partido Villarreal-Espanyol por la emergencia meteorológica.'\n",
      "      Peso: 0.9846\n",
      "   'La Aemet retira también el aviso rojo por fuertes lluvias en Castellón, que se mantiene en naranja.'\n",
      "      Peso: 0.9734\n",
      "\n",
      " Tópico 2:\n",
      "   'Los premios Oscar dan la gloria al cine indie y castigan una vez más a Netflix'\n",
      "      Peso: 0.9871\n",
      "   'Reino Unido y otros países aliados de Ucrania se comprometen a rearmar a Zelenski: 'Botas en el terreno y aviones en los cielos''\n",
      "      Peso: 0.9814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Documentos más representativos por tópico\n",
    "print(\"\\n DOCUMENTOS MÁS REPRESENTATIVOS POR TÓPICO\")\n",
    "print(\"Se muestran los documentos que más peso tienen en cada tópico\\n\")\n",
    "\n",
    "for topic_idx in range(n_topics):\n",
    "    print(f\" Tópico {topic_idx + 1}:\")\n",
    "    # Obtener los documentos más representativos\n",
    "    top_doc_indices = np.argsort(doc_topics[:, topic_idx])[::-1][:no_top_documents]\n",
    "\n",
    "    for doc_idx in top_doc_indices:\n",
    "        title = df.iloc[doc_idx][\"Titular\"]\n",
    "        weight = doc_topics[doc_idx, topic_idx]\n",
    "        print(f\"   '{title}'\")\n",
    "        print(f\"      Peso: {weight:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc31211e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Suspendido el partido Villarreal-Espanyol por la emergencia meteorológica.</th>\n",
       "      <td>0.985</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reino Unido y otros países aliados de Ucrania se comprometen a rearmar a Zelenski: 'Botas en el terreno y aviones en los cielos'</th>\n",
       "      <td>0.019</td>\n",
       "      <td>0.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los premios Oscar dan la gloria al cine indie y castigan una vez más a Netflix</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emilia Pérez, Karla Sofía Gascón, Demi Moore y la decencia, a la cabeza de los perdedores de la noche</th>\n",
       "      <td>0.022</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La Aemet retira también el aviso rojo por fuertes lluvias en Castellón, que se mantiene en naranja.</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>España propone financiar la defensa de los países de la UE con fondos europeos</th>\n",
       "      <td>0.965</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>El tequila lubricó la gran noche en la que Hollywood no quiso hablar de Donald Trump</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trump congela toda la ayuda militar a Ucrania para castigar y doblegar a Zelenski</th>\n",
       "      <td>0.961</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La Comunidad Valenciana y otras cinco regiones, bajo aviso por lluvia</th>\n",
       "      <td>0.185</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Objetivo: acabar con la pesca fantasma y las redes abandonadas que matan y mutilan tortugas en el Mediterráneo</th>\n",
       "      <td>0.056</td>\n",
       "      <td>0.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los científicos abandonan el sueño de crear ‘vida espejo’, que podría convertirse en pesadilla</th>\n",
       "      <td>0.961</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valladolid ya no permite más terrazas cerradas y niega las últimas once licencias.</th>\n",
       "      <td>0.049</td>\n",
       "      <td>0.951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   topic0 topic1\n",
       "Suspendido el partido Villarreal-Espanyol por l...  0.985  0.015\n",
       "Reino Unido y otros países aliados de Ucrania s...  0.019  0.981\n",
       "Los premios Oscar dan la gloria al cine indie y...  0.013  0.987\n",
       "Emilia Pérez, Karla Sofía Gascón, Demi Moore y ...  0.022  0.978\n",
       "La Aemet retira también el aviso rojo por fuert...  0.973  0.027\n",
       "España propone financiar la defensa de los país...  0.965  0.035\n",
       "El tequila lubricó la gran noche en la que Holl...  0.027  0.973\n",
       "Trump congela toda la ayuda militar a Ucrania p...  0.961  0.039\n",
       "La Comunidad Valenciana y otras cinco regiones,...  0.185  0.815\n",
       "Objetivo: acabar con la pesca fantasma y las re...  0.056  0.944\n",
       "Los científicos abandonan el sueño de crear ‘vi...  0.961  0.039\n",
       "Valladolid ya no permite más terrazas cerradas ...  0.049  0.951"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para mostrar matriz documento-tópico\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "topicnames = [\"topic\" + str(x) for x in range(0, lda.n_components)]\n",
    "norm_doc_topics = []\n",
    "for i in doc_topics:\n",
    "    norm_doc_topics.append([\"{0:.3f}\".format(weight) for weight in i])\n",
    "\n",
    "df = pd.DataFrame(norm_doc_topics, columns=topicnames, index=df[\"Titular\"].tolist())\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36681059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>100</th>\n",
       "      <th>106</th>\n",
       "      <th>143</th>\n",
       "      <th>180</th>\n",
       "      <th>2017</th>\n",
       "      <th>2024</th>\n",
       "      <th>500</th>\n",
       "      <th>abundancia</th>\n",
       "      <th>academia</th>\n",
       "      <th>...</th>\n",
       "      <th>vieron</th>\n",
       "      <th>viles</th>\n",
       "      <th>volod</th>\n",
       "      <th>voluntad</th>\n",
       "      <th>willem</th>\n",
       "      <th>ximo</th>\n",
       "      <th>xito</th>\n",
       "      <th>zelenski</th>\n",
       "      <th>zonas</th>\n",
       "      <th>zorrilla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic0</th>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.004206</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.004209</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic1</th>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.002937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 390 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             000       100       106       143       180      2017      2024  \\\n",
       "topic0  0.000579  0.000582  0.004247  0.004189  0.004206  0.000553  0.000561   \n",
       "topic1  0.002948  0.002939  0.000371  0.000400  0.000396  0.002947  0.002938   \n",
       "\n",
       "             500  abundancia  academia  ...    vieron     viles     volod  \\\n",
       "topic0  0.004209    0.000569  0.000552  ...  0.004200  0.004228  0.004178   \n",
       "topic1  0.000393    0.002929  0.002944  ...  0.000376  0.000394  0.000394   \n",
       "\n",
       "        voluntad    willem      ximo      xito  zelenski     zonas  zorrilla  \n",
       "topic0  0.004127  0.000543  0.004255  0.000539  0.004147  0.000572  0.000549  \n",
       "topic1  0.000417  0.002958  0.000384  0.002931  0.000418  0.002920  0.002937  \n",
       "\n",
       "[2 rows x 390 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz tópico-palabra\n",
    "\n",
    "# Matriz tema-palabra clave\n",
    "df_topic_keywords = pd.DataFrame(\n",
    "    lda.components_ / lda.components_.sum(axis=1)[:, np.newaxis]\n",
    ")\n",
    "\n",
    "# Asignar columnas e índice\n",
    "df_topic_keywords.columns = dictionary\n",
    "df_topic_keywords.index = topicnames\n",
    "\n",
    "# Ver\n",
    "df_topic_keywords.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc5b0d",
   "metadata": {},
   "source": [
    "**Evaluación del modelo**\n",
    "\n",
    "Utilizamos dos métricas principales:\n",
    "\n",
    "1. Log Likelihood (mayor es mejor):\n",
    "   * Indica cómo de bien el modelo explica los datos\n",
    "   * Valores más altos indican mejor ajuste\n",
    "\n",
    "2. Perplejidad (menor es mejor):\n",
    "   * Mide qué tan \"sorprendido\" está el modelo por los datos\n",
    "   * Valores más bajos indican mejor generalización\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08557eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÉTRICAS DE EVALUACIÓN\n",
      "- Log Likelihood: -3732.99\n",
      "- Perplejidad: 943.43\n",
      "\n",
      "COMPARACIÓN DE HIPERPARÁMETROS\n",
      "Probando diferentes configuraciones para encontrar el mejor modelo...\n",
      "\n",
      "Resultados con diferentes números de tópicos:\n",
      "   n_topics  perplexity  log_likelihood\n",
      "0         2  878.213841    -3693.950115\n",
      "1         4  801.510384    -3644.141370\n",
      "2         6  775.912329    -3626.451547\n",
      "3         8  865.176829    -3685.798982\n"
     ]
    }
   ],
   "source": [
    "# Calcular métricas\n",
    "log_likelihood = lda.score(bag_of_words)\n",
    "perplexity = lda.perplexity(bag_of_words)\n",
    "\n",
    "print(\"MÉTRICAS DE EVALUACIÓN\")\n",
    "print(f\"- Log Likelihood: {log_likelihood:.2f}\")\n",
    "print(f\"- Perplejidad: {perplexity:.2f}\")\n",
    "\n",
    "# Comparar con diferentes valores de hiperparámetros\n",
    "print(\"\\nCOMPARACIÓN DE HIPERPARÁMETROS\")\n",
    "print(\"Probando diferentes configuraciones para encontrar el mejor modelo...\")\n",
    "\n",
    "# Probar diferentes números de tópicos\n",
    "n_topics_range = [2, 4, 6, 8]\n",
    "results = []\n",
    "\n",
    "for n_top in n_topics_range:\n",
    "    model = LatentDirichletAllocation(\n",
    "        n_components=n_top,\n",
    "        doc_topic_prior=alpha,\n",
    "        topic_word_prior=beta,\n",
    "        max_iter=25,\n",
    "        random_state=0,\n",
    "    )\n",
    "    model.fit(bag_of_words)\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"n_topics\": n_top,\n",
    "            \"perplexity\": model.perplexity(bag_of_words),\n",
    "            \"log_likelihood\": model.score(bag_of_words),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Mostrar resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nResultados con diferentes números de tópicos:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486f8642",
   "metadata": {},
   "source": [
    "### Apartado b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44b342ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto analizado: 'Trump ordena suspender toda la ayuda militar de Estados Unidos a Ucrania tras su bronca a Zelenski.'\n",
      "Distribución de tópicos:\n",
      "Tópico 1: 78.78% ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\n",
      "Tópico 2: 21.22% ▓▓▓▓▓▓▓▓▓▓\n"
     ]
    }
   ],
   "source": [
    "text = \"Trump ordena suspender toda la ayuda militar de Estados Unidos a Ucrania tras su bronca a Zelenski.\"\n",
    "vector = tf_vectorizer.transform([text])\n",
    "topic_dist = lda.transform(vector)[0]\n",
    "\n",
    "print(f\"Texto analizado: '{text}'\")\n",
    "print(\"Distribución de tópicos:\")\n",
    "\n",
    "# Mostrar cada tópico con su probabilidad\n",
    "for idx, prob in enumerate(topic_dist, 1):\n",
    "    bar = \"▓\" * int(prob * 50)  # Barra visual simple\n",
    "    print(f\"Tópico {idx}: {prob:.2%} {bar}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "03-representacion-texto (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 5: Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "Hacer fine-tuning de BERT para análisis de sentimientos sobre opiniones de películas con el dataset rotten_tomatoes de HuggingFace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado a\n",
    "Consultar datos del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset_builder, get_dataset_split_names\n",
    "\n",
    "ds = load_dataset_builder(\"rotten_tomatoes\")\n",
    "\n",
    "print(\"Descripción del dataset: \", ds.info.description)\n",
    "print(\"Características del dataset: \", ds.info.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_split_names(\"rotten_tomatoes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado b\n",
    "Cargar el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "\n",
    "labels = dataset['train'].features['label'].names\n",
    "NUM_LABELS = len(labels)\n",
    "print('Labels: ', labels, ', número de labels: ', NUM_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado c\n",
    "Tokenización con el tokenizer de BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = max([len(tokenizer(text).input_ids) for text in dataset['train']['text']])\n",
    "print(\"Tamaño máximo en el train: \", MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", max_length=MAX_LENGTH)\n",
    "\n",
    "\n",
    "encoded_data = dataset.map(tokenize, batched=True)\n",
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = encoded_data[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_validation_dataset = encoded_data[\"validation\"].shuffle(seed=42).select(range(500))\n",
    "small_test_dataset = encoded_data[\"test\"].shuffle(seed=42).select(range(500))\n",
    "\n",
    "full_train_dataset = encoded_data[\"train\"]\n",
    "full_validation_dataset = encoded_data[\"validation\"]\n",
    "full_test_dataset = encoded_data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    index = random.randint(0, small_train_dataset.num_rows)\n",
    "    print('text:', index, ' len:', len(small_train_dataset[index]['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado d\n",
    "Cargar modelo preentrenado y configurar hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=NUM_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(output_dir=\"./outputs\", report_to=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado e\n",
    "Definir métricas y entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    y_true = pred.label_ids\n",
    "    y_pred = pred.predictions.argmax(-1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_validation_dataset,\n",
    "    args=args,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado f\n",
    "Evaluar en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text):\n",
    "    inputs = tokenizer(text, padding=\"max_length\", max_length=MAX_LENGTH, truncation=True, return_tensors=\"pt\").to(model.device)\n",
    "    pred = model(**inputs).logits\n",
    "    probs = pred.softmax(1)\n",
    "    return probs.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = [get_prediction(text) for text in small_test_dataset['text']]\n",
    "y_true = small_test_dataset['label']\n",
    "\n",
    "print(classification_report(y_true=y_true, y_pred=y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "Utilizar el modelo entrenado para inferir sobre textos nuevos no presentes en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = [\n",
    "    'i hate you too much',\n",
    "    'I did not like the film at all',\n",
    "    'I loved the movie'\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    inputs = tokenizer(text, padding=\"max_length\", max_length=MAX_LENGTH, truncation=True, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model(**inputs)\n",
    "    probs = outputs.logits.softmax(1)\n",
    "\n",
    "    print(f\"Texto: '{text}'\")\n",
    "    print(f\"Probabilidades: {probs}\")\n",
    "    print(f\"Predicción: {labels[probs.argmax().item()]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ix74lzees6o",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "Comparar distintos modelos preentrenados para la misma tarea de análisis de sentimientos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado a\n",
    "Definir lista de modelos a comparar y función de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "model_ids = [\n",
    "    \"bert-base-cased\",\n",
    "    \"distilbert-base-uncased\",\n",
    "    \"albert-base-v2\",\n",
    "    \"xlm-roberta-base\",\n",
    "]\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "labels = dataset['train'].features['label'].names\n",
    "NUM_LABELS = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    y_true = pred.label_ids\n",
    "    y_pred = pred.predictions.argmax(-1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(model_id):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Modelo: {model_id}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    MAX_LENGTH = max([len(tokenizer(text).input_ids) for text in dataset['train']['text']])\n",
    "\n",
    "    def tokenize(batch):\n",
    "        return tokenizer(batch[\"text\"], padding=\"max_length\", max_length=MAX_LENGTH)\n",
    "\n",
    "    encoded_data = dataset.map(tokenize, batched=True)\n",
    "\n",
    "    small_train = encoded_data[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "    small_val = encoded_data[\"validation\"].shuffle(seed=42).select(range(500))\n",
    "    small_test = encoded_data[\"test\"].shuffle(seed=42).select(range(500))\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=NUM_LABELS)\n",
    "\n",
    "    args = TrainingArguments(output_dir=f\"./outputs_{model_id.replace('/', '_')}\", report_to=\"none\")\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_dataset=small_train,\n",
    "        eval_dataset=small_val,\n",
    "        args=args,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    def get_prediction(text):\n",
    "        inputs = tokenizer(text, padding=\"max_length\", max_length=MAX_LENGTH, truncation=True, return_tensors=\"pt\").to(model.device)\n",
    "        pred = model(**inputs).logits\n",
    "        return pred.softmax(1).argmax().item()\n",
    "\n",
    "    y_pred = [get_prediction(text) for text in small_test['text']]\n",
    "    y_true = small_test['label']\n",
    "\n",
    "    print(classification_report(y_true=y_true, y_pred=y_pred, target_names=labels))\n",
    "\n",
    "    return model_id, accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado b\n",
    "Entrenar y evaluar todos los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for model_id in model_ids:\n",
    "    model_name, accuracy = train_and_evaluate_model(model_id)\n",
    "    results.append((model_name, accuracy))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUMEN DE RESULTADOS\")\n",
    "print(\"=\"*60)\n",
    "for model_name, accuracy in results:\n",
    "    print(f\"{model_name}: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "05-transformers (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
